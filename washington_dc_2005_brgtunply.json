{
    "LayerId": "GMU.washington_dc_2005_brgtunply",
    "Name": "washington_dc_2005_brgtunply",
    "CollectionId": "geoserver",
    "Institution": "GMU",
    "Access": "Public",
    "DataType": "Polygon",
    "Availability": "online",
    "LayerDisplayName": "Bridges and Tunnels, Washington, DC 2006",
    "Publisher": "",
    "Originator": "DC GIS",
    "OriginatorSort": "DC GIS",
    "GeoReferenced": true,
    "Abstract": "This polygon layer represents the Bridges and polygons in Washington, DC 2006",
    "Location": "{\"wfs\": \"https://gmutantt.gmu.edu/geoserver/GMUGeodata/wfs\",\"wms\": [\"https://gmutantt.gmu.edu/geoserver/GMUGeodata/wms\"]}",
    "MaxY": 38.9913,
    "MinY": 38.793,
    "MaxX": -76.9115,
    "MinX": -77.1168,
    "CenterX": -77.01415,
    "CenterY": 38.89215,
    "HalfWidth": 0.10264999999999702,
    "HalfHeight": 0.09915000000000163,
    "Area": 0.04071098999999949,
    "WorkspaceName": "",
    "ContentDate": "2005-01-01 01:01:01+00:00",
    "timestamp": "2020-08-01 00:29:52.642000+00:00",
    "FgdcText": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<metadata>\n  <idinfo>\n    <citation>\n      <citeinfo>\n        <origin>DC GIS</origin>\n        <pubdate>2006</pubdate>\n        <title>Bridges and Tunnels, Washington, DC 2006</title>\n        <geoform>vector digital data</geoform>\n      <ftname Sync=\"TRUE\">washington_dc_2005_brgtunply</ftname>\n</citeinfo>\n    </citation>\n    <descript>\n      <abstract>This polygon layer represents the Bridges and polygons in Washington, DC 2006</abstract>\n      <purpose>This data is used for the planning and management of Washington, D.C. by local government agencies.</purpose>\n    </descript>\n    <timeperd>\n      <timeinfo>\n        <sngdate>\n          <caldate>04/04/2005</caldate>\n        </sngdate>\n      </timeinfo>\n      <current>ground condition</current>\n    </timeperd>\n    <status>\n      <progress>Complete</progress>\n      <update>Unknown</update>\n    </status>\n    <spdom>\n      <bounding>\n        <westbc>-77.1168</westbc>\n        <eastbc>-76.9115</eastbc>\n        <northbc>38.9913</northbc>\n        <southbc>38.7930</southbc>\n      </bounding>\n    </spdom>\n    <keywords>\n      <theme>\n        <themekt>Transportation</themekt>\n        <themekey>Bridge\t</themekey>\n        <themekey>Tunnel</themekey>\n      </theme>\n      <place>\n        <placekt>Washington, DC</placekt>\n        <placekey>District of Columbia</placekey>\n        <placekey>DC</placekey>\n      </place>\n    </keywords>\n    <accconst>Contact OCTO GIS.  Any data obtained outside of OCTO GIS are unauthorized copies.</accconst>\n    <useconst>Data cannot be redistributed in any manner without written authorization. OCTO makes no claims as to the completeness, accuracy or content of any data contained hereon, and makes no representation of any kind, including, but not limited to, the warranty of the accuracy or fitness for a  particular use, nor are any such warranties to be implied or inferred with respect to the information or data furnished herein.</useconst>\n    <ptcontac>\n      <cntinfo>\n        <cntorgp>\n          <cntorg>D.C. Office of the Chief Technology Office</cntorg>\n        </cntorgp>\n        <cntpos>GIS Data Coordinator</cntpos>\n        <cntaddr>\n          <addrtype>mailing and physical</addrtype>\n          <address>441 4th St NW, Suite 930 South</address>\n          <city>Washington</city>\n          <state>DC</state>\n          <postal>20001</postal>\n        </cntaddr>\n        <cntvoice>(202) 727-2277</cntvoice>\n        <cntemail>dcgis@dc.gov</cntemail>\n      </cntinfo>\n    </ptcontac>\n    <datacred>D.C. Office of the Chief of Technology Officer (OCTO)</datacred>\n    <native>Microsoft Windows XP Version 5.1 (Build 2600) Service Pack 2; ESRI ArcCatalog 9.1.0.722</native>\n  </idinfo>\n  <dataqual>\n    <attracc>\n      <attraccr>Validated by source and/or responsible agency.</attraccr>\n    </attracc>\n    <logic>OCTO developed and operated a QA/QC program to check the deliverables.  Generally, the program consists of various types of processes grouped into visual checks, automated procedures, edge-matching routines, specialized checks, and field verification. Through the application of these processes, the data's spatial and attribute accuracy, usability, data documentation adherence, and specialized characteristics are checked.   \n\nStaff identified issues in a shape file with appropriate descriptions for the vendor to fix.  The data was delivered in preliminary format for a thorough review and identification of issues.  The vendor fixed the data and delivered final data which OCTO checked to ensure the vendor made the fixes appropriately.</logic>\n    <complete>Validated by source and/or responsible agency.</complete>\n    <posacc>\n      <horizpa>\n        <horizpar>For the 1999 data that was not updated in 2005, it was mapped at a 1:1000 scale. This means that the horizontal accuracy is guaranteed to meet National Map Accuracy standards at 1:1000, which calls for 90% of well defined points to fall within .85 feet of true position.  This is slightly more accurate that the 2005 data\n\nFor the 2005 data, the horizontal accuracy of the orthorectified images is mainly determined by the accuracy of the aero triangulation and digital surface model (DSM).  For each rectified image, an RMSE value for all of the standard errors of the tie/pass/control points located in that image and computed by the aerotriangulation solution was calculated. The DSM accuracy assessment was achieved by comparing the aerotriangulation-derived elevation with the elevation of the DSM.  In addition, visual examination was employed to assess all tiles and its relative edge match.  All results were examined for consistency and its compliance with the ASPRS Standards for Large Scale Mapping at 1 to 1200 which indicates that the orthos will meet 1 foot RMSE at the 95% certainty level.</horizpar>\n      </horizpa>\n      <vertacc>\n        <vertaccr>A formal accuracy assessment of the vertical positional information in the data set has either not been conducted, or is not applicable </vertaccr>\n      </vertacc>\n    </posacc>\n    <lineage>\n      <srcinfo>\n        <srccite>\n          <citeinfo>\n            <origin>EarthData International, Inc</origin>\n            <pubdate>08/04/06</pubdate>\n            <title>Aerial Photography of Washington, D.C.</title>\n            <geoform>remote-sensing image</geoform>\n          </citeinfo>\n        </srccite>\n        <typesrc>filmstrip</typesrc>\n        <srctime>\n          <timeinfo>\n            <sngdate>\n              <caldate>20050404</caldate>\n            </sngdate>\n          </timeinfo>\n          <srccurr>ground condition</srccurr>\n        </srctime>\n        <srccitea>Aerial Photography</srccitea>\n        <srccontr>This aerial photography was composed of 24 flight lines and a total of 1023 exposures.  Imagery was obtained at an altitude of 1,100 meters above mean terrain (AMT) 7200.\n\nThe mission was flown with two Wild RC30 cameras serial no. 5368 with 153.743 mm lens serial number 13413 and serial no. 5324 with 153.247 mm lens serial number 13365 with ABGPS.</srccontr>\n      </srcinfo>\n      <srcinfo>\n        <srccite>\n          <citeinfo>\n            <origin>TerraSurv, Inc</origin>\n            <pubdate>08/01/05</pubdate>\n            <title>Report of Survey Washington, DC Area</title>\n            <geoform>model</geoform>\n          </citeinfo>\n        </srccite>\n        <typesrc>electronic mail system</typesrc>\n        <srctime>\n          <timeinfo>\n            <sngdate>\n              <caldate>20050801</caldate>\n            </sngdate>\n          </timeinfo>\n          <srccurr>ground condition</srccurr>\n        </srctime>\n        <srccitea>GPS ground control</srccitea>\n        <srccontr>TerraSurv established 30 photo identification control points to support the aerotriangulation process. Continuously Operating Reference Station (CORS) station USNO (PIDAI7403) was used as the control for this project. The horizontal datum was the North American Datum of 1983, CORS adjustment (NAD 1983 CORS).  The vertical datum was the North American Vertical Datum of 1988\n(NAVD 1988).</srccontr>\n      </srcinfo>\n      <procstep>\n        <procdesc>Dataset copied from the CD obtained from Washington DC 2005\n\nThis process describes data originally captured in 1999 and applies to features not updated in 2005.  The CAPTURE YEAR field contains the data of origin for the feature.\n\nEarthdata Maryland (EDMD) transferred control points, pass and tie points from the 1995 analytical aerotriangulation solution.  Control was transferred from 1995 working diapositives to diapositives of the new photography.  Control points were transferred optically using a Wild PUG 4-point transfer device equipped with a 60-micron drill.\n\nEDMD acquired new aerial photography of the District of Columbia in the spring of 1999 prior to the emergence of deciduous foliage.  Aerial photography was exposed at an altitude of 7,200' AMT using a Wild RC-20 or RC-30 camera system that is equipped with forward motion compensation and a 12\" (300mm) focal length lens cone 600'.  \n\nThe flight design developed in 1995 was duplicated.  The design calls for an approximate total of 1,000 frames in 24 North-South oriented flight lines.  Forward overlap between frames within each flight line was 80%.  Sidelap between adjacent flight lines was 48%.  Aerial photography was captured in natural color using Kodak Aerocolor negative film type 2445.  Aerial photography was not exposed using airborne GPS due to the existence of an existing control network created in 1995.\n\nEDMD produced 2 full sets of contact prints.  The prints were separated into a total of 4 sets of prints, 2 sets of even frames and 2 sets of odd frames.  Three of these sets were delivered to NCPC for distribution to the District.  One set was held by EDMD for reference purposes.  The project manager determined if an odd or even set was withheld for work purposes. The planimetric mapping was developed using a set of stable base color film diapositives that are created from the 1999 photography. EDMD produced a flight line index of the completed photography.  The positions of the photographs as recorded by the ASCOT navigation/control system was plotted over an existing raster or vector map of the District of Columbia.  EDMD delivered 3 plots of the completed index to NCPC.\n\nPlanimetric Data Capture and Edit:\n\nThe following is a step-by-step description of the steps involved in the collection of planimetric features from the aerial photography. \n\nStep 1\tPlanimetric data is captured within each flightline proceeding in an North-South or South-North progression.  The diapositives and contact prints for each of the priority production areas are assigned to photogrammetric technician for data collection.  All planimetric data is collected using Wild BC-2 first order analytical stereoplotting systems.\n\nStep 2\tThe photogrammetric supervisor establishes the data collection conventions to be used for data capture.  All planimetric data is initially collected in the Microstation environment.  The photogrammetric supervisor establishes data collection conventions and establishes the data-layering schema, global origin and working units to be used for data collection.  These preferences are programmed into Microstation to ensure continuity. \n\nStep 3\tPlanimetric data is collected and saved to the designated network subdirectory.  As data is collected, the technician reviews the planimetric information on the stereoplotter monitor to ensure that collection is complete and that the required features are depicted and assigned to the correct layer in the CAD design file.  EDMD has developed an in-house CAD application to prepare the planimetric features for conversion to polygons once the data has been migrated into ARC/INFO.  The technician collects planimetric features in a clockwise direction, which create centroids at the completion of each line.  Each of these centroids delineates the outer boundary of a polygon.  In areas where a line creates a boundary for multiple features (edge of pavement, edge of parking lot, edge of parking lot-edge of building), the line segment is duplicated and assigned to all layers of the file that contain the effected features.\n\nStep 4\tThe photogrammetric technician completes information for inclusion in the metadata.\n\nStep 5\tAs stereo models are completed on the analytical stereoplotter, the cartographic editor copies a number of files pertaining to a block of map coverage and merges the data sets into map-sheet-oriented format.  The merged data is inspected for compliance with the database design.\nCriteria for inspection include correct layer assignment, line color, and line style.  The CAD application has incorporated quality control functions, which add temporary symbols to indicate the\nnecessary duplication of line segments to complete polygon closure in all affected features.  The editor makes any corrections or additions interactively.  If necessary, lines are snapped to ensure closure.\n\nStep 5A\tThe cartographic editor translates the ARC/INFO coverages of the existing planimetric data that was produced as part of Task 2 and the State Department modification into a CAD readable format.  The line work between the new mapping and existing mapping is tied together to ensure compliance with the contract requirements for topology.\n\nStep 6\tAs coverage areas are completed; the editor informs the ARC/INFO supervisor that data is ready for conversion and final quality control.  The completed vector files are copied to a designated network subdirectory. In order to avoid the possibility that incomplete or unedited data sets are mistakenly imported during production, a separate network subdirectory is used for the data at each\nstage in the production process.  The network subdirectory structure is standardized for every project.\n\nStep 7\tEdited data sets are translated into ARC/INFO and polygon topology is created.  The process used to create the final ARC/INFO coverages is described in the Attribute Accuracy Report Section.\n\nStep 8\tThe cartographic technician records any pertinent dates or other information for completion of metadata.\n\nQA/QC Plots\n\nEDMD developed an ARC/INFO AML to generate hard copy plots of the 1995 digital orthophotos as part of Task.  This routine will be modified to accommodate plotting of the planimetric and/or topographic data.  The format will retain the graphic design that was developed in 1999. Design elements of the format and surround as well as the planimetric/topographic mapping will be fully compliant with the requirements stated in the contract modification. Upon completion of the initial editing and conversion of the data to ARC/INFO, EDMD will prepare a set of bond paper plots.  Polygon features will be color coded for cartographic clarity and will enable NCPC quality inspectors to verify that no polygons overlap or are miscoded.  A copy of the digital data that corresponds to the plots will be included to allow inspectors to review digital data content.  NCPC will inspect the plots and mark any errors, omissions or mistakes on the plots.  The edited plots are returned to\nEDMD for correction.  Once the data has been corrected, EDMD will produce a total of 3 sets of inkjet mylar plots containing the planimetric data only in the approved format surround.\n\nARC/INFO coverage development\n\nExtracted from Librarian using Simple option into coverage, then imported to geodatabase. Removed all voids and empty polygons from shape. The NCPC ArcInfo Librarian dataset is made up of 350 tiles.  Over 29 data layers were extracted from the Librarian using the following procedures (see planimetric process.xls).\n\n1) In order to withdraw seamless data out of Librarian an extraction polygon must be created.  The extraction polygon must encompass the span of all the tiles.  Extracting the index layer of the librarian and dissolving the boundaries of the 350 polygons into 1 polygon accomplished this task.\n\nThe procedures for creating the extraction polygon are as follows:\n¨\tExtract the index layer using Arcview and converting the theme into a shapefile.\n¨\tCreate a field within the feature table for which the individual polygon can dissolve from by assigning a value of 1 in it for all records.\n¨\tUsing the geo-processor extension option, the shapefiles' records were dissolved into 1 poly by dissolving the records with the common field.\n¨\tThe polygon theme was then transformed into a polygon coverage through ArcToolbox.\n¨\tOnce the extraction polygon was prepped, data layer extraction was completely done in the ArcInfo environment.\n\nSetting the ArcInfo Environment.\n1)\tLaunch the ArcInfo Command Prompt window.\n2)\tSet the working directory ( arc:  w d:\\workspace\\extraction)\n3)\tSet the precision for the environment and to all processes done in the ArcInfo Session.  ( arc:  Precision double double  )\n4)\tEnter the librarian module  (arc:  Librarian)\n5)\tSet the library volume (Librarian:  library ncpc)\n6)\tSet the extraction polygon coverage (Librarian: setcover index)\n7)\tSet the layer to be extracted  (Librarian : setlayer air)\n8)\tEnter the command line to extract.  (Librarian:  extract OPTION # clip)\n\nThe extract command has a few options that can be set when extracting different types of layers such as polygons, lines, and points. Extract DISSOLVE is used for polygon layers only because it will extract the layer and merge the polygons where they are split by index tiles, thus removing additional polys.  The ArcInfo commands involved with this option are Clip Dissolve and Build.\n\nFor Line and Point layers, the SIMPLE option was used to extract.  The topology is left unbuilt when the information is extracted.  Reason being that if the tile lines segment lines and create pseudo nodes.  The user-id from the ArcInfo table were used to unsplit the lines and remove the pseudo node.  Once that is done, the coverage can rebuild the topology.\n\nData Improvements\n\nThe line data coverages had tiles with some additional pseudo nodes.  The pseudo nodes were probably created as a result of different digitizing techniques (neither right nor wrong).  Using the Unsplit command we were able to clean these areas up by unsplitting only lines that had the same dxf-layer value and that shared a node.\n\nData cleanup\n\nThe polygon coverages extracted contained void (coded 9999) areas.  In Arcedit, these ambiguous features were removed with the following technique.\nArc:  ae  (enter arcedit module)\n\nArcedit: ec coverage  (enter the editing coverage)\n\nArcedit:  ef poly (enter the feature to be edited)\n\nArcedit: select for dxf-layer = 'VOID'  (querying for features in the attribute table under dxf-layer that contains attribute labeled VOID)\n\nArcedit:  delete (delete the features found)\n\nArcedit: Save  (save the changes)\n\nThe line coverages had the neatlines using the same method where the dxf-layer had values = 'NEATLINE'\n\nCreating Shapefiles\nAll data sets were converted into shapefiles and clipped to the DC Boundary for import into the geodatabase.\n\nFrom the Arc: prompt window, the command ARCSHAPE was used to create the shape coverages.  This required the user to specify which coverage to convert, the feature class, and naming convention of the output shapefile.</procdesc>\n        <procdate>1999</procdate>\n        <srcprod>1999 data capture</srcprod>\n        <proccont>\n          <cntinfo>\n            <cntorgp>\n              <cntorg>EarthData International, Inc</cntorg>\n            </cntorgp>\n            <cntaddr>\n              <addrtype>mailing and physical address</addrtype>\n              <address>7320 Executive Way</address>\n              <city>Frederick</city>\n              <state>MD</state>\n              <postal>21704</postal>\n              <country>USA</country>\n            </cntaddr>\n            <cntvoice>(301)948-8550</cntvoice>\n            <cntfax>(301)963-2064</cntfax>\n            <cntemail>metadata@earthdata.com</cntemail>\n          </cntinfo>\n        </proccont>\n      </procstep>\n      <procstep>\n        <procdesc>Analytical Aerotriangulation:\n\nSource photography -  Wild RC-30 camera, natural color stable base.\nControl - airborne GPS supplemented with photo identifiable field control.\nScanning -  Z/I Imaging PhotoScan flatbed metric scanner. \nAerotriangulation -  Photo-T.\nElevation Model -  Lidar, autocorrelation and manual collection and update.\nRadiometric Balancing - Proprietary and COTS Software (PhotoShop).\nOrthorectification -  Z/I Ortho Pro 4.0 software package.\nMosaic -  Z/I Ortho Pro 4.0 software package.\nProcessed on Windows NT/2000 systems.\n\nThe ground control and airborne GPS data was integrated into a rigid network through the completion of a fully analytical bundle aerotriangulation adjustment.\n\n1. The original aerial film was scanned at a resolution of 21 microns. The scans were produced using Z/I Imaging PhotoScan flatbed metric scanners.\n\n2. The raster scans were given a preliminary visual check on the scanner workstation to ensure that the raster file size is correct and to verify that the tone and contrast were acceptable.  A directory tree structure for the project was established on one of the workstations. This project was then accessed by other workstations through the network. The criteria used for establishment of the directory structure and file naming conventions accessed through the network avoids confusion or errors due to inconsistencies in digital data. The project area was defined using the relevant camera information that was obtained from the USGS camera calibration report for the aerial camera and the date of photography. The raster files were rotated to the correct orientation for mensuration on the softcopy workstation.  The rotation of the raster files was necessary to accommodate different flight directions from one strip to the next. The technician verified that the datum and units of measurement for the supplied control were consistent with the project requirements.\n\n3. The photogrammetric technician performed an automatic interior orientation for the frames in the project area.  The softcopy systems that were used by the technicians have the ability to set up predefined fiducial templates for the aerial camera(s) used for the project. Using the template that was predefined in the interior orientation setup, the software identified and measured the eight fiducial positions for all the frames.  Upon completion, the results were reviewed against the tolerance threshold.  Any problems that occurred during the automatic interior orientation would cause the software to reject the frame and identify it as a potential problem. The operator then had the option to measure the fiducials manually.\n\n4. The operator launched the point selection routine which automatically selected pass and tie points by an autocorrelation process. The correlation tool that is part of the routine identified the same point of contrast between multiple images in the Von Gruber locations. The interpolation tool can be adjusted by the operator depending on the type of land cover in the triangulation block. Factors that influence the settings include the amount of contrast and the sharpness of features present on the photography.   A preliminary adjustment was run to identify pass points that had high residuals. This process was accomplished for each flight line or partial flight line to ensure that the network has sufficient levels of accuracy. The points were visited and the cause for any inaccuracy was identified and rectified. This process also identified any gaps where the point selection routine failed to establish a point.  The operator interactively set any missing points.\n\n5. The control and pass point measurement data was run through a final adjustment on the Z/I SSK PhotoT workstations. The PhotoT program created a results file with the RMSE results for all points within the block and their relation to one another.  The photogrammetrist performing the adjustments used their experience to determine what course of action to take for any point falling outside specifications.\n\n6. The bundle adjustment was run through thePhotoT software several times.  The photogrammetrist increased the accuracy parameters for each subsequent iteration so, when the final adjustment was run, the RMSE for the project met the accuracy of 1 part in 10,000 of the flying height for the horizontal position (X and Y) and 1 part in 9,000 or better of the flying height in elevation (Z).  The errors were expressed as a natural ratio of the flying height utilizing a one-sigma (95%) confidence level.\n\n7. The accuracy of the final solution was verified by running the final adjustment, placing no constraints on any quality control points. The RMSE values for these points must fall within the tolerances above for the solution to be acceptable.\n\n8. The final adjustment generates three files.  The .txt file has all the results from the adjustment with the RMSE values for each point measured. The .XYZ file contains the adjusted X, Y, Z,coordinates for all the measured points and the .PHT file contains the exterior orientation parameters of each exposure station.</procdesc>\n        <procdate>20060630</procdate>\n        <srcprod>Analytical Aerotriangulation</srcprod>\n        <proccont>\n          <cntinfo>\n            <cntorgp>\n              <cntorg>EarthData International, Inc</cntorg>\n            </cntorgp>\n            <cntaddr>\n              <addrtype>mailing and physical address</addrtype>\n              <address>7320 Executive Way</address>\n              <city>Frederick</city>\n              <state>MD</state>\n              <postal>21704</postal>\n              <country>USA</country>\n            </cntaddr>\n            <cntvoice>(301)948-8550</cntvoice>\n            <cntfax>(301)963-2064</cntfax>\n            <cntemail>metadata@earthdata.com</cntemail>\n          </cntinfo>\n        </proccont>\n      </procstep>\n      <procstep>\n        <procdesc>Digital Elevation Model (DEM):\n\nBoth Lidar and previously produced DEM data was available to support the production process.  Following an analysis of the data the previously produced DEM was selected for update and use.\n\nThe following provides a step-by-step outline of the production process.\n\n1.  The existing DEM which was comprised of both gridded mass points from 10 to 20 meters with spots, and vertices of contour lines was converted to dgn files for compilation.\n\n2.  The DEM was then merged together in Micro Station V8, and then split into 34 tiles, approximately 3077m X 3029m.\n\n3.  The compilation team updated the data with break lines where needed, and collected 3D bridges.  3D bridges were collected to prevent smearing and warping, caused by the elevation difference between the bare earth and the elevated bridges.  Proprietary MDLs for Micro station were run to create a 10 to 15 meter buffer around the bridges and to clip the surrounding ground data.\n\n4.  The dgn files were then merged into four large areas for QC purposes.  The files were imported into Terra Solid/Terra Modler and a tin and a color relief was generated to search for any spikes or mismatches.  This check in performed to fix any problems before going to the ortho stage.  Large water areas were filled with elevation points.\n\n5.  Complex lines, shapes and arcs were dropped before delivering to the ortho department.  A final level listing was run to ensure all the lines were dropped and the files were clean.  This listing was provided to the ortho team.</procdesc>\n        <procdate>20060630</procdate>\n        <srcprod>Digital Elevation Model (DEM)</srcprod>\n        <proccont>\n          <cntinfo>\n            <cntorgp>\n              <cntorg>EarthData International, Inc</cntorg>\n            </cntorgp>\n            <cntaddr>\n              <addrtype>mailing and physical address</addrtype>\n              <address>7320 Executive Way</address>\n              <city>Frederick</city>\n              <state>MD</state>\n              <postal>21704</postal>\n              <country>U.S.</country>\n            </cntaddr>\n            <cntvoice>(301)948-8550</cntvoice>\n            <cntfax>(301)963-2064</cntfax>\n            <cntemail>metadata@earthdata.com</cntemail>\n          </cntinfo>\n        </proccont>\n      </procstep>\n      <procstep>\n        <procdesc>Planimetric Data Capture:\n\nThe following planimetric layers were either updated from previous datasets or, created during the production process -\n\n-  Building Polygons (BldgPly)\n-  Bridge and Tunnel Polygons (BrgTunPly)\n-  Horizontal and Vertical Control Points (GeoControlPt)\n-  Hydrography Center Lines (HydroCenterLineLn)\n-  Metro Entrance Points (MetroEntPt)\n-  Obscured Area Polygons (ObsAreaPly)\n-  Railroad Lines (RailRdLn)\n-  Road, Parking, and Driveway Polygons (RoadPly)\n-  Sidewalk Polygons (SidewalkPly)\n-  Under Construction Areas (UnderConstPly)\n-  Wooded Areas (WoodPly)\n\nThe following guidelines were used for the collection of hydrography centerlines -  Hydrography lines were collected in the direction of flow through the center of all visible stream course features.   Hydrography centerlines were coded as hidden where streams flowed  underneath features that obstructed visibility such as bridges  and overpasses.  Areas between visible stream courses, where the  actual course could not be confidently determined based on  stereo-photography, were connected using a separate connector code.\n\nThe following guidelines were used for the collection of  obscured areas -  Obscured area polygons were delineated in areas where features could not be confidently determined based on stereo-photography.  Such instances included areas of deep shade or heavy vegetation.\n\nThe following guidelines were used for data capture and change detection:\n\nFor layers tagged as update through change detection, features were removed if they no longer existed in the photography, added if new, or modified if the geometry changed (i.e. building additions).  All layers carry a date of capture to delineate which features have been updated.  \n\nFor change detection methodology, Earthdata thoroughly reviewed the downtown area, mapping tiles that covered the downtown core, for change detection on all of the layers.  Outside the downtown area, the contractor carefully reviewed the surrounding area for change detection on all of the layers ONLY WHERE THERE WERE BUILDING OR ROAD CHANGES.\n\nThe following processes were involved in updating existing planimetric data levels -\n\n1.  Client supplied planimetric data from 1999 was received as merged ESRI shapefile layers.\n\n2.  Client supplied layers were converted into Microstation DGN format  for updating in the stereo compilation environment. The conversion process involved clipping the merged layers into more manageable tile based files.  Polygon feature codes were maintained and updated in the Microstation environment through the use of unique text annotation to define polygon centroid labels.\n\n3.  The Microstation linework was draped to existing DEM points to create 3D datasets that could be updated in a  stereo compilation environment.\n\n4.  The Microstation tiles were updated using the 2005 stereo imagery. Any updated features were coded to reflect a change in status from existing to new.\n\n5.  The final updated tiles were checked for proper attribution and coding.\n\n6.  The tile datasets were converted into ESRI Geodatabase format for final topological and visual quality control.\n\n7.  The Geodatabase topology was checked against a rules file to detect any dangles in linework along with overlapping and intersecting features.\n\n8.  Polygon datasets were checked for adjacent areas containing the same code along with multiple code labels within the same polygon.\n\n9.  A visual check using the 2005 orthophotography was performed to look for and correct any improper attribution or missing features.\n\n10.  A final Geodatabase file was prepared based on the DC OCTO planimetric data structure.</procdesc>\n        <procdate>20060719</procdate>\n        <srcprod>Planimetric Layers</srcprod>\n        <proccont>\n          <cntinfo>\n            <cntorgp>\n              <cntorg>EarthData International, Inc</cntorg>\n            </cntorgp>\n            <cntaddr>\n              <addrtype>mailing and physical address</addrtype>\n              <address>7320 Executive Way</address>\n              <city>Frederick</city>\n              <state>MD</state>\n              <postal>21704</postal>\n              <country>U.S.</country>\n            </cntaddr>\n            <cntvoice>(301)948-8550</cntvoice>\n            <cntfax>(301)963-2064</cntfax>\n            <cntemail>metadata@earthdata.com</cntemail>\n          </cntinfo>\n        </proccont>\n      </procstep>\n      <procstep>\n        <procdesc>\nData copied from CD obtained from D.C.</procdesc>\n        <srcused>E:\\DCGISDATA_WORKSPACE\\OCTO\\plan2005template.xml</srcused>\n        <procdate>unknown</procdate>\n      </procstep>\n    </lineage>\n  </dataqual>\n  <spdoinfo>\n    <direct>Vector</direct>\n    <ptvctinf>\n      <sdtsterm>\n        <sdtstype>G-polygon</sdtstype>\n        <ptvctcnt>628</ptvctcnt>\n      </sdtsterm>\n    </ptvctinf>\n  </spdoinfo>\n  <spref>\n    <horizsys>\n      <planar>\n        <gridsys>\n          <gridsysn>State Plane Coordinate System 1983</gridsysn>\n          <spcs>\n            <spcszone>1900</spcszone>\n            <lambertc>\n              <stdparll>38.3</stdparll>\n              <stdparll>39.45</stdparll>\n              <longcm>-77.0</longcm>\n              <latprjo>0.0</latprjo>\n              <feast>400000.0</feast>\n              <fnorth>0.0</fnorth>\n            </lambertc>\n          </spcs>\n        </gridsys>\n        <planci>\n          <plance>coordinate pair</plance>\n          <coordrep>\n            <absres>0.6096</absres>\n            <ordres>0.6096</ordres>\n          </coordrep>\n          <plandu>meters</plandu>\n        </planci>\n      </planar>\n      <geodetic>\n        <horizdn>North_American_Datum_1983</horizdn>\n        <ellips>GRS_1980</ellips>\n        <semiaxis>6378137.0</semiaxis>\n        <denflat>298.257222101</denflat>\n      </geodetic>\n    </horizsys>\n  </spref>\n  <eainfo>\n    <detailed>\n      <enttyp>\n        <enttypl>BrgTunPly.shp Attribute Table</enttypl>\n        <enttypd>Table containing attribute information associated with the data set.</enttypd>\n        <enttypds>Producer Defined</enttypds>\n      </enttyp>\n      <attr>\n        <attrlabl>FID</attrlabl>\n        <attrdef>Internal feature number.</attrdef>\n        <attrdefs>ESRI</attrdefs>\n        <attrdomv>\n          <udom>Sequential unique whole numbers that are automatically generated.</udom>\n        </attrdomv>\n      </attr>\n      <attr>\n        <attrlabl>Shape</attrlabl>\n        <attrdef>Feature geometry.</attrdef>\n        <attrdefs>ESRI</attrdefs>\n        <attrdomv>\n<udom>Coordinates defining the features.</udom>\n        </attrdomv>\n      </attr>\n      <attr>\n        <attrlabl>GIS_ID</attrlabl>\n        <attrdef/>\n        <attrdefs>Producer Defined</attrdefs>\n        <attrdomv>\n<udom/>\n        </attrdomv>\n      </attr>\n      <attr>\n        <attrlabl>FEATURECOD</attrlabl>\n        <attrdef/>\n        <attrdefs>Producer Defined</attrdefs>\n        <attrdomv>\n<rdom>\n            <rdommin>1500</rdommin>\n            <rdommax>1520</rdommax>\n          </rdom>\n        </attrdomv>\n      </attr>\n      <attr>\n  <attrlabl>DESCRIPTIO</attrlabl>\n<attrdef/>\n<attrdefs>Producer Defined</attrdefs>\n<attrdomv>\n    <edom>\n      <edomv>Bridge</edomv>\n      <edomvd>\n      </edomvd>\n      <edomvds>Producer defined</edomvds>\n    </edom>\n  </attrdomv>\n  <attrdomv>\n    <edom>\n      <edomv>Tunnel Entrance</edomv>\n      <edomvd>\n      </edomvd>\n      <edomvds>Producer defined</edomvds>\n    </edom>\n  </attrdomv>\n  <attrdomv>\n    <edom>\n      <edomv>Hidden Bridge</edomv>\n      <edomvd>\n      </edomvd>\n      <edomvds>Producer defined</edomvds>\n    </edom>\n  </attrdomv>\n</attr>\n      <attr>\n  <attrlabl>CAPTUREYEA</attrlabl>\n<attrdef/>\n<attrdefs>Producer Defined</attrdefs>\n<attrdomv>\n    <edom>\n      <edomv>1999-03-31</edomv>\n      <edomvd>\n      </edomvd>\n      <edomvds>Producer defined</edomvds>\n    </edom>\n  </attrdomv>\n  <attrdomv>\n    <edom>\n      <edomv>2005-04-04</edomv>\n      <edomvd>\n      </edomvd>\n      <edomvds>Producer defined</edomvds>\n    </edom>\n  </attrdomv>\n</attr>\n      <attr>\n        <attrlabl>NAME</attrlabl>\n        <attrdef/>\n        <attrdefs>Producer Defined</attrdefs>\n        <attrdomv>\n<udom/>\n        </attrdomv>\n      </attr>\n      <attr>\n        <attrlabl>SHAPE_Leng</attrlabl>\n        <attrdef/>\n        <attrdefs>Producer Defined</attrdefs>\n        <attrdomv>\n<rdom>\n            <rdommin>3.92317735327</rdommin>\n            <rdommax>5112.63005622</rdommax>\n          </rdom>\n        </attrdomv>\n      </attr>\n      <attr>\n        <attrlabl>SHAPE_Area</attrlabl>\n        <attrdef/>\n        <attrdefs>Producer Defined</attrdefs>\n        <attrdomv>\n<rdom>\n            <rdommin>0.45146749998</rdommin>\n            <rdommax>33633.841243</rdommax>\n          </rdom>\n        </attrdomv>\n      </attr>\n    </detailed>\n  </eainfo>\n  <distinfo>\n    <distrib>\n      <cntinfo>\n        <cntorgp>\n          <cntorg>George Mason University Libraries</cntorg>\n          <cntper>Digital Scholarship Center</cntper>\n        </cntorgp>\n        <cntaddr>\n          <addrtype>mailing and physical</addrtype>\n          <address>4400 University Drive</address>\n          <city>Fairfax</city>\n          <state>VA</state>\n          <postal>22030</postal>\n        </cntaddr>\n        <cntvoice>703-993-2240</cntvoice>\n        <cntemail>datahelp@gmu.edu</cntemail>\n      </cntinfo>\n    </distrib>\n    <resdesc Sync=\"TRUE\">Downloadable Data</resdesc>\n    <distliab>Distributor assumes no liability for misuse of data.</distliab>\n    <stdorder>\n      <digform>\n<digtinfo>\n          <formname>Digital Data</formname>\n        </digtinfo>\n        <digtopt>\n<onlinopt>\n<computer>\n<networka>\n<networkr/>\n</networka>\n</computer>\n</onlinopt>\n</digtopt>\n</digform>\n      <fees>None. No fees are applicable for obtaining the data set</fees>\n    </stdorder>\n  </distinfo>\n  <metainfo>\n    <metd>20200607</metd>\n    <metc>\n      <cntinfo>\n        <cntorgp>\n          <cntorg>George Mason University Libraries</cntorg>\n          <cntper>Digital Scholarship Center</cntper>\n        </cntorgp>\n        <cntaddr>\n          <addrtype>mailing and physical</addrtype>\n          <address>4400 University Drive</address>\n          <city>Fairfax</city>\n          <state>VA</state>\n          <postal>22030</postal>\n        </cntaddr>\n        <cntvoice>703-993-2240</cntvoice>\n        <cntemail>datahelp@gmu.edu</cntemail>\n      </cntinfo>\n    </metc>\n    <metstdn>FGDC Content Standards for Digital Geospatial Metadata</metstdn>\n    <metstdv>FGDC-STD-001-1998</metstdv>\n    <mettc Sync=\"TRUE\">local time</mettc>\n  </metainfo>\n</metadata>\n",
    "DataTypeSort": "Polygon",
    "_version_": 1673780833962426368,
    "LayerDisplayNameSort": "Bridges and Tunnels, Washington, DC 2006",
    "PublisherSort": "",
    "InstitutionSort": "GMU",
    "score": 3.55876
}